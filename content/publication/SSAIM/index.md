---
title: Sparse and Smooth Additive Isotonic Model in High-Dimensional Settings
publication_types:
  - "2"
authors:
  - admin
  - Yiqin Wang
  - Meng Wang
  - Beilun Wang
doi: https://doi.org/10.1007/s10994-024-06641-9
publication: Machine Learning
abstract: "Smooth additive isotonic models (SAIM) are used in trend analysis to model the response of nonparametric smooth monotone prediction functions. The relationship between multiple environmental indicators and environmental pollution is a typical SAIM case. Previous methods for estimating SAIM are sub-optimal and computationally expensive in high-dimensional settings, where the number of variables is larger than the number of samples. To address these problems, we hybridize a variable selection procedure with smooth additive isotonic models and propose a novel model called Sparse Smooth Additive Isotonic Model (SSAIM). Our model first solves the variable selection to reduce problem complexities and computational costs. Then, the smooth monotone prediction functions are efficiently estimated via a block coordinate gradient descent algorithm. We theoretically show that SSAIM achieves a state-of-the-art error bound. Experiments on multiple simulated and real-world datasets demonstrate that integrating sparsity and smoothness constraints in SSAIM helps improve model prediction accuracy and sparsity of large models. Moreover, SSAIM spends much less time compared with multivariate non-sparse models and the increment of time cost brought about by smoothness constraint is little compared with multivariate sparse models."
draft: false
featured: false
image:
  filename: featured
  focal_point: Smart
  preview_only: false
date: 2024-10-22T04:00:52.017Z

url_code: https://github.com/ZJQxxn/SSAIM
---